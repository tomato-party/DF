{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"15IZ9p5Od_7SF2kcWlx7Dmn5SbS0FUi0B","timestamp":1685446020559}],"authorship_tag":"ABX9TyO/bFciV/MReg2/Duh74nMQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0Pw8mCHWZew","executionInfo":{"status":"ok","timestamp":1685447938017,"user_tz":-540,"elapsed":2551,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"68f57b33-d60c-48b3-a19e-1afbff13afa1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["#!pip install --upgrade tensorflow"],"metadata":{"id":"xNjT8wdyWhIm","executionInfo":{"status":"ok","timestamp":1685447938018,"user_tz":-540,"elapsed":6,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#!pip install keras"],"metadata":{"id":"Ny82cibsWi3u","executionInfo":{"status":"ok","timestamp":1685447938018,"user_tz":-540,"elapsed":6,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["#!pip install tqdm"],"metadata":{"id":"2sdF0tviWj8l","executionInfo":{"status":"ok","timestamp":1685447938018,"user_tz":-540,"elapsed":5,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import keras.utils\n","from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n","from keras.preprocessing import image\n","from tqdm import tqdm\n","#from tensorflow.keras.preprocessing.image import load_img\n","#from tensorflow.keras.preprocessing.image import img_to_array\n","\n","import tensorflow\n","import tensorflow.keras\n","print(tensorflow.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-Xe5q2ZWmC_","executionInfo":{"status":"ok","timestamp":1685447938018,"user_tz":-540,"elapsed":5,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"e44f252e-3b3b-49e4-b25b-e3876d41ae39"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["2.12.0\n"]}]},{"cell_type":"code","source":["# VGG-16 모델 불러오기\n","model = VGG16(weights='imagenet')"],"metadata":{"id":"RwZbypIrWnWY","executionInfo":{"status":"ok","timestamp":1685447959822,"user_tz":-540,"elapsed":21808,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","\n","img_path = '/content/drive/MyDrive/TS_PS/'\n","img_list = os.listdir(img_path)\n","img_list[0]"],"metadata":{"id":"uvezmR6GWool","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1685447959822,"user_tz":-540,"elapsed":11,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"d3b802a5-d552-4102-941a-05ed622bfce8"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'PS_031_1.jpg'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["#from tensorflow.python.keras import utils\n","from keras.utils import load_img\n","from keras.utils import img_to_array"],"metadata":{"id":"QN87A-bdWqGb","executionInfo":{"status":"ok","timestamp":1685447959822,"user_tz":-540,"elapsed":3,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def image_to_nparray(image):\n","    image_array = np.asarray(image)\n","    return image_array"],"metadata":{"id":"HUNxb9IfWrMV","executionInfo":{"status":"ok","timestamp":1685447959823,"user_tz":-540,"elapsed":4,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["img_np = []\n","for i in tqdm(img_list[:10]):\n","\n","  # 모델 사이즈로 이미지 파일을 읽기\n","  img = load_img(img_path+i,target_size=(224,224))\n","  \n","  # 이미지 데이터를 numpy로 변환\n","  x = image_to_nparray(img)\n","  img_np.append(x)\n","\n","images_nparray = np.array(img_np)\n","#print(images_nparray.shape)\n","\n","images_nparray = np.expand_dims(images_nparray, axis=0)\n","images_nparray = preprocess_input(images_nparray)"],"metadata":{"id":"Dc9o9kZiWsPJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685447961634,"user_tz":-540,"elapsed":1815,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"2e50c048-705b-4d60-905f-6f51e5c647ee"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:01<00:00,  6.56it/s]\n"]}]},{"cell_type":"code","source":["# 프레임 수 변경\n","images_nparray = images_nparray[:, 0]  # 첫 번째 프레임만 선택\n","\n","# 결과 확인\n","print(images_nparray.shape)  # 이미지들의 NumPy 배열의 형태 출력\n","\n","# VGG-16 모델에 입력\n","predictions = model.predict(images_nparray)"],"metadata":{"id":"sUEEL5kvWtjK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685447963459,"user_tz":-540,"elapsed":1829,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"9bcae741-4b91-4b28-cede-6e133de03fb9"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 224, 224, 3)\n","1/1 [==============================] - 2s 2s/step\n"]}]},{"cell_type":"code","source":["# 이미지 분류 예측\n","preds = model.predict(images_nparray)\n","pred_classes = decode_predictions(preds, top=3)[0]  # 상위 3개 예측 결과 가져오기"],"metadata":{"id":"CfphnEm4Wu1i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685447964694,"user_tz":-540,"elapsed":1236,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"ae6159a1-c432-4a4c-ef6d-1f1cf9581f77"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 1s 1s/step\n"]}]},{"cell_type":"code","source":["# 결과 출력\n","print('예측 결과:')\n","for pred in pred_classes:\n","    print(f'{pred[1]}: {pred[2] * 100:.2f}%')"],"metadata":{"id":"C4h20hvcWwH0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685447964695,"user_tz":-540,"elapsed":6,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"757f56dc-b7df-4d30-a28c-d92340fc66f2"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["예측 결과:\n","buckle: 52.80%\n","Band_Aid: 8.62%\n","switch: 8.03%\n"]}]},{"cell_type":"code","source":["# train/ test 나눠서 vgg 학습시키기"],"metadata":{"id":"5PXBYTqJXmJ5","executionInfo":{"status":"ok","timestamp":1685447964695,"user_tz":-540,"elapsed":5,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["import PIL\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import json\n","import os\n","from tqdm import tqdm\n","from PIL import Image"],"metadata":{"id":"anKOoepGWxcn","executionInfo":{"status":"ok","timestamp":1685447964696,"user_tz":-540,"elapsed":5,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["trans = transforms.Compose([\n","    transforms.Resize((224, 224)),  # 이미지 크기 조정\n","    transforms.ToTensor(),  # 이미지를 텐서로 변환\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 이미지 정규화\n","])\n"," \n","dataset = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/', transform = trans)"],"metadata":{"id":"7i5KF9VpWzGN","colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"status":"error","timestamp":1685457659876,"user_tz":-540,"elapsed":284,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"e0d8827a-8f05-4875-ed3b-3b1a637be500"},"execution_count":61,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-7f9388c7f604>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes Colab Notebooks, PS, npy. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torchvision.models as models\n","from torchvision import transforms\n","\n","# .npy 파일 경로\n","data_path = \"/content/drive/MyDrive/npy/ps_data.npy\"\n","label_path = \"/content/drive/MyDrive/npy/ps_class.npy\"\n","\n","# 데이터 로드\n","data = np.load(data_path, allow_pickle=True)\n","labels = np.load(label_path, allow_pickle=True)"],"metadata":{"id":"s5SKotDCW0c9","executionInfo":{"status":"ok","timestamp":1685451753802,"user_tz":-540,"elapsed":11416,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["print(data.shape)\n","print(labels.shape)"],"metadata":{"id":"L8jJjVFAW1x0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685451759825,"user_tz":-540,"elapsed":353,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"bd3fd70e-7991-4aea-96d7-806556020c4d"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["(930, 3, 256, 256)\n","(930,)\n"]}]},{"cell_type":"code","source":["# 데이터셋 분할 (훈련 데이터셋과 테스트 데이터셋)\n","train_ratio = 0.8\n","train_size = int(train_ratio * len(data))\n","\n","X_train = data[:train_size]\n","y_train = labels[:train_size]\n","X_test = data[train_size:]\n","y_test = labels[train_size:]"],"metadata":{"id":"oe9txVe4W22n","executionInfo":{"status":"ok","timestamp":1685451762047,"user_tz":-540,"elapsed":281,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# 전처리\n","X_train = torch.tensor(X_train).float()\n","y_train = torch.tensor(y_train)\n","X_test = torch.tensor(X_test).float()\n","y_test = torch.tensor(y_test)\n","\n","\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# 테스트 데이터셋 전처리\n","test_dataset = [(transform(image), label) for image, label in zip(X_test, y_test)]\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"18rJ0_1zW4EO","executionInfo":{"status":"ok","timestamp":1685451767270,"user_tz":-540,"elapsed":3312,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["# VGG-16 모델 불러오기\n","model = models.vgg16(pretrained=True)\n","model.eval()  # 평가 모드로 설정"],"metadata":{"id":"IL-ghKF-W5zm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685451779384,"user_tz":-540,"elapsed":10227,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"a8806cbe-e4e6-4bd0-d639-62a713a050de"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:06<00:00, 79.6MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["# 정확도 계산 함수\n","\n","def compute_accuracy(model, dataloader):\n","    global predicted\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            #images = images.cuda()\n","            #labels = labels.cuda()\n","\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy"],"metadata":{"id":"TG9PiKm7W7EB","executionInfo":{"status":"ok","timestamp":1685451784262,"user_tz":-540,"elapsed":332,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# 정확도 계산\n","accuracy = compute_accuracy(model, test_loader)\n","print(f\"Test Accuracy: {accuracy:.2f}%\")"],"metadata":{"id":"AChkyMrrW8Sr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685451915652,"user_tz":-540,"elapsed":128681,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"2d0ae2e6-8c99-4d43-a9bb-a75c54f81318"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.00%\n"]}]},{"cell_type":"code","source":["## train set으로 훈련시킨 후 test set과 비교"],"metadata":{"id":"htsWMAi9XwGz","executionInfo":{"status":"ok","timestamp":1685451919896,"user_tz":-540,"elapsed":257,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["data = data[...,:3]\n","print(data.shape)"],"metadata":{"id":"QceGIInDW9f-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685451921141,"user_tz":-540,"elapsed":2,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"665bcdfd-efef-40cc-c643-8fb52cce25c6"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["(930, 3, 256, 3)\n"]}]},{"cell_type":"code","source":["print(data.dtype)\n","data = data.astype(np.float64)\n","print(data.dtype)\n","\n","data_tensor = torch.from_numpy(data)\n","#labels_tensor = torch.from_numpy(labels)"],"metadata":{"id":"vYfbyxlUW-h4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685451922793,"user_tz":-540,"elapsed":393,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"8bf21df7-8bb0-4688-c81a-51d1a75cf700"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["float32\n","float64\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms\n","from sklearn.model_selection import train_test_split\n","\n","# 데이터셋 분할 (훈련 데이터셋과 테스트 데이터셋)\n","X_train, X_test, y_train, y_test = train_test_split(data_tensor, labels, test_size=0.2, random_state=42)\n","\n","# 이미지 변환 및 데이터셋 구성\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"],"metadata":{"id":"wuZazCKQW_0o","executionInfo":{"status":"ok","timestamp":1685451926679,"user_tz":-540,"elapsed":1747,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, labels, transform=None):\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, index):\n","        image = self.data[index]\n","        label = self.labels[index]\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        return image, label"],"metadata":{"id":"PwEWYJogXBRA","executionInfo":{"status":"ok","timestamp":1685452002390,"user_tz":-540,"elapsed":284,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["train_dataset = CustomDataset(X_train, y_train, transform)\n","test_dataset = CustomDataset(X_test, y_test, transform)\n","\n","# 데이터로더 설정\n","batch_size = 32\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"xT9BnJD8XCgH","executionInfo":{"status":"ok","timestamp":1685452021440,"user_tz":-540,"elapsed":347,"user":{"displayName":"한유승","userId":"00932910509418673182"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# VGG-16 모델 불러오기 (미리 학습된 가중치 사용)\n","model = models.vgg16(pretrained=True)\n","num_features = model.classifier[6].in_features\n","model.classifier[6] = nn.Linear(num_features, len(np.unique(labels)))  # 레이블 개수에 맞는 출력 노드 설정\n","\n","# 손실 함수와 옵티마이저 설정\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"],"metadata":{"id":"M0WJOKz4XDdb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685452026009,"user_tz":-540,"elapsed":2039,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"8f447e4b-f5b8-42e2-a98b-faa8424a9abb"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["# 모델 학습\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    \n","    for inputs, labels in train_loader:\n","        #inputs = inputs.to(device)\n","        #labels = labels.to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item() * inputs.size(0)\n","    \n","    epoch_loss = running_loss / len(train_dataset)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"],"metadata":{"id":"DNlx9j-UXEi2","colab":{"base_uri":"https://localhost:8080/","height":405},"executionInfo":{"status":"error","timestamp":1685452050630,"user_tz":-540,"elapsed":22326,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"9ba487fd-72ef-4a92-930a-15185b76e079"},"execution_count":59,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-59ee35dee38f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: Target 2 is out of bounds."]}]},{"cell_type":"code","source":["# 테스트 데이터셋을 사용하여 정확도 예측\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        #inputs = inputs.to(device)\n","        #labels = labels.to(device)\n","        \n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs, 1)\n","        \n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = correct / total\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n"],"metadata":{"id":"iRr4yC0SXGdJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685452186645,"user_tz":-540,"elapsed":125562,"user":{"displayName":"한유승","userId":"00932910509418673182"}},"outputId":"dd356aae-e96b-44d0-e0ef-91d4f76f6169"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.0000\n"]}]}]}